#!/usr/bin/env python

#stdlib imports
import urllib.request as request
import urllib
import re
import json
import os.path
import tempfile
import datetime
import sys
import argparse
import calendar

#local imports
from eqconvert import ndk
from eqconvert.convert import create_quakeml

QUICKURL = 'http://www.ldeo.columbia.edu/~gcmt/projects/CMT/catalog/NEW_QUICK/qcmt.ndk'
MONTHLYURL = 'http://www.ldeo.columbia.edu/~gcmt/projects/CMT/catalog/NEW_MONTHLY/'
COMCATBASE = 'http://earthquake.usgs.gov/earthquakes/eventpage/[EVENTID]'
#COMCATBASE = 'http://comcat.cr.usgs.gov/earthquakes/eventpage/[EVENTID]'
DEVCOMCATBASE = 'http://dev-earthquake.cr.usgs.gov/earthquakes/eventpage/[EVENTID]'
#DEVCOMCATBASE = 'http://dev-earthquake.cr.usgs.gov/earthquakes/eventpage/[EVENTID]'
TIMEFMT = '%Y-%m-%d %H:%M:%S.%f'

def writeQuakeML(xmlstr,eventid,outfolder):
    fname = os.path.join(outfolder,eventid+'.xml')
    f = open(fname,'wt')
    f.write(xmlstr)
    f.close()

def getQuickNDK():
    ndkfilename = None
    try:
        fh = request.urlopen(QUICKURL)
        data = fh.read().decode('utf-8')
        f,ndkfilename = tempfile.mkstemp(suffix='.ndk')
        os.close(f)
        ndkfile = open(ndkfilename,'wt')
        ndkfile.write(data)
        ndkfile.close()
        fh.close()
    except:
        pass
    return ndkfilename

def addMonth(dinput):
    year = dinput.year
    month = dinput.month
    if dinput.month == 12:
        month = 1
        year += 1
    else:
        month += 1
    doutput = datetime.datetime(year,month,1)
    return doutput

def getAllMonths(lastreviewed):
    months = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']
    endofmonth = datetime.datetime(1990,1,1)
    ndkfiles = []
    try:
        fh = request.urlopen(MONTHLYURL)
        data = fh.read().decode('utf-8')
        fh.close()
        matches = re.findall('>[0-9]{4}\/<',data)
        matches = sorted(matches)
        ndkfiles = []
        for match in matches:
            myear = int(match[1:5])
            checkdate = datetime.datetime(myear,1,1)
            if checkdate <= lastreviewed:
                continue
            tndkfiles,tmonth = getYearMonths(myear,lastreviewed)
            if tmonth > endofmonth:
                endofmonth = tmonth
            ndkfiles += tndkfiles
    except Exception as message:
        raise Exception('Could not retrieve data from %s.  Message: "%s"' % (MONTHLYURL,message.message))

    return (ndkfiles,endofmonth)

def getYearMonths(year,lastreviewed):
    months = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']
    ndkfiles = []
    yearurl = urllib.parse.urljoin(MONTHLYURL,str(year)+'/')
    fh = request.urlopen(yearurl)
    data = fh.read().decode('utf-8')
    fh.close()
    endofmonth = datetime.datetime(1990,1,1)
    pat = '[a-z]{3}[0-9]{2}\.ndk'
    matches = re.findall(pat,data)
    matches = list(set(matches)) #unique values
    eventmonths = []
    for match in matches:
        eyear = int(match[3:5]) + 2000
        emonth = months.index(match[0:3]) + 1
        monthstart = datetime.datetime(eyear,emonth,1)
        wkday,numdays = calendar.monthrange(eyear,emonth)
        monthend = datetime.datetime(eyear,emonth,numdays,23,59,59)
        if monthend > endofmonth:
            endofmonth = monthend
        if monthstart > lastreviewed:
            ndkurl = urllib.parse.urljoin(yearurl,match)
            ndkfiles.append(getMonthlyNDK(ndkurl))
    return (ndkfiles,endofmonth)
    
def getRecentMonths(lastreviewed):
    ndkfiles = []
    try:
        fh = request.urlopen(MONTHLYURL)
        data = fh.read().decode('utf-8')
        fh.close()
        matches = re.findall('>[0-9]{4}\/<',data)
        matches = sorted(matches)
        endyear = int(matches[-1][1:5])
        tndkfiles,endofmonth = getYearMonths(endyear,lastreviewed)
        ndkfiles += tndkfiles
    except Exception as message:
        raise Exception('Could not retrieve data from %s.  Message: "%s"' % (MONTHLYURL,message.message))
    return (ndkfiles,endofmonth)

def getMonthlyNDK(ndkurl):
    f,ndkfilename = tempfile.mkstemp(suffix='.ndk')
    os.close(f)
    fh = request.urlopen(ndkurl)
    data = fh.read().decode('utf-8')
    fh.close()
    ndkfile = open(ndkfilename,'wt')
    ndkfile.write(data)
    ndkfile.close()
    return ndkfilename

def eventInComCat(event,isdev=False):
    gcmtid = 'gcmt'+event['id']
    if not isdev:
        url = COMCATBASE.replace('[EVENTID]',gcmtid)
    else:
        url = DEVCOMCATBASE.replace('[EVENTID]',gcmtid)
    inComCat = True
    try:
        fh = request.urlopen(url)
        fh.close()
    except:
        inComCat = False
    return inComCat

def main(args):
    homedir = os.path.expanduser('~') #user's home directory

    #this text file should have key:pair values
    lastprocessedfile = os.path.join(homedir,'lastprocessed.txt')
    processdict = {'lastreviewed':datetime.datetime(2010,1,1),'lastquick':datetime.datetime(2010,1,1)}
    if os.path.isfile(lastprocessedfile):
        f = open(lastprocessedfile,'rt')
        for line in f.readlines():
            pkey,pvalue = line.strip().split('=')
            if pkey == 'lastreviewed':
                processdict['lastreviewed'] = datetime.datetime.strptime(pvalue.strip(),TIMEFMT)
            if pkey == 'lastquick':
                processdict['lastquick'] = datetime.datetime.strptime(pvalue.strip(),TIMEFMT)
        f.close()


    #download our monthly ndk file and our quick file
    mndkfiles,lastreviewed = getAllMonths(processdict['lastreviewed'])
    newstart = processdict['lastquick']
    if lastreviewed > newstart:
        newstart = lastreviewed - datetime.timedelta(days=7)
    else:
        newstart = processdict['lastquick'] - datetime.timedelta(days=7)

    #process quick solutions first
    qndkfile = getQuickNDK()
    nquick = 0
    if qndkfile is None: #couldn't get the quick CMT files
        sys.exit(1)
    allevents = ndk.get_events(qndkfile,catalog=args.catalog,contributor=args.contributor)
    for event in allevents:
        #any quick events that are older than the most recent quick events should not be processed
        if event['origins'][0]['time'] <= processdict['lastquick']:
            continue

        sys.stderr.write('Writing QuakeML for quick event %s %s\n' % (event['id'],event['origins'][0]['time']))
        quakeml = create_quakeml(event)
        writeQuakeML(quakeml,event['id'],args.folder)
        nquick += 1
        if event['origins'][0]['time'] > processdict['lastquick']:
            processdict['lastquick'] = event['origins'][0]['time']

    #clean up quick NDK file
    os.remove(qndkfile)
    
    #now process monthly reviewed stuff, if we have a new monthly file at all
    if not len(mndkfiles):
        #tell the user what just happened
        print('%i quick events parsed.' % nquick)
        print('0 reviewed events parsed.')
        sys.exit(0)

    nreviewed = 0
    for mndkfile in mndkfiles:
        for event in ndk.get_events(mndkfile):
            #any reviewed events that are older than the most recent reviewed events should not be processed
            if event['origins'][0]['time'] <= processdict['lastreviewed']:
                continue
            sys.stderr.write('Writing QuakeML for reviewed event %s %s\n' % (event['id'],event['origins'][0]['time']))
            quakeml = create_quakeml(event)
            nreviewed += 1
            writeQuakeML(quakeml,event['id'],args.folder)
            if event['origins'][0]['time'] > processdict['lastreviewed']:
                processdict['lastreviewed'] = event['origins'][0]['time']

    #Update the lastprocessed text file
    f = open(lastprocessedfile,'wt')
    f.write('lastreviewed=%s\n' % processdict['lastreviewed'].strftime(TIMEFMT))
    f.write('lastquick=%s\n' % processdict['lastquick'].strftime(TIMEFMT))
    f.close()

    #tell the user what just happened
    print('%i quick events parsed.' % nquick)
    print('%i reviewed events parsed.' % nreviewed)
        
    #clean up after ourselves
    for mndkfile in mndkfiles:
        os.remove(mndkfile)
    sys.exit(0)

if __name__ == '__main__':
    desc = '''Download all post 2010 GCMT events, or those that have appeared since the last run, and convert to QuakeML.

    This program saves state in a text file stored in the user's home directory called 'lastprocessed.txt'.
    This file contains two lines that will look something like this:

    lastreviewed=2016-02-29 23:50:40.299999
    lastquick=2016-07-07 10:12:09.099999

    GCMT events are published twice - once as "quick" solutions done within approximately 16 hours of the event, 
    and again as "reviewed" solutions done several months after the fact.
    
    If the file above exists, it is interpreted in the following way:

    Any quick event that is found on the GCMT website where the origin date is before 2016-07-07 10:12:09.099999 will not be processed.
    Any reviewed event that is found on the GCMT website where the origin date is before 2016-02-29 23:50:40.299999 will not be processed.

    The converted QuakeML files are written to the folder specified as the positional argument to the program.
    '''
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    #folder is required, so making it a positional argument
    parser.add_argument('folder', help='Specify output folder where QuakeML should be written.')
    parser.add_argument('--catalog',default='us',
                        help='Specify data catalog.')
    parser.add_argument('--contributor',default='us',
                        help='Specify data catalog.')
    pargs = parser.parse_args()
    main(pargs)
    
    
